{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "id": "dT9AQwdf8sJK"
   },
   "source": [
    "# Digital Mentor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hideCode": false,
    "id": "Qgo-oaI3JU2u",
    "outputId": "94e8f443-9ef2-4460-a642-3f8229dc08cf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from base64 import b64encode\n",
    "import time\n",
    "import torch\n",
    "import utils\n",
    "import api_utils\n",
    "from openai import OpenAI\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import elevenlabs as elevlabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths to media files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "hideCode": false,
    "hideOutput": false,
    "id": "vsphzJawLF-f",
    "outputId": "6700a71e-e87e-41a0-b78a-4abae7b7a843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90% 90% ./media/Albert/results/result.mp4\n",
      "Albert\n",
      "Clone image found: ./media/Albert/image.jpg\n",
      "Clone video found: ./media/Albert/presentation.mp4\n",
      "Clone goodbye video found: ./media/Albert/goodbye.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def seleccion(personaje='Albert', verbose=False):\n",
    "    # What character to use\n",
    "    clone_to_use = personaje # \"Steve\"\n",
    "    global input_video,presentation_video,goodbye_video,results_path,w_vid,h_vid\n",
    "    # Path to the media directory containing\n",
    "    # the avatar image, welcome video and goodbye videos\n",
    "    path = f\"./media/\"\n",
    "    \n",
    "    input_video = path + f\"{clone_to_use}/image.jpg\"\n",
    "    presentation_video = path + f\"{clone_to_use}/presentation.mp4\"\n",
    "    goodbye_video = path + f\"{clone_to_use}/goodbye.mp4\"\n",
    "    results_path = path + f\"{clone_to_use}/results/result.mp4\"\n",
    "    w_vid = h_vid = \"90%\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(w_vid,h_vid,results_path)\n",
    "\n",
    "        print(clone_to_use)\n",
    "        if os.path.isfile(input_video):\n",
    "            print(f\"Clone image found: {input_video}\")\n",
    "        else:\n",
    "            print(f\"CLONE IMAGE NOT FOUND: {input_video}\")\n",
    "\n",
    "        if os.path.isfile(presentation_video):\n",
    "            print(f\"Clone video found: {presentation_video}\")\n",
    "        else:\n",
    "            print(f\"CLONE VIDEO NOT FOUND: {presentation_video}\")\n",
    "\n",
    "        if os.path.isfile(goodbye_video):\n",
    "            print(f\"Clone goodbye video found: {goodbye_video}\")\n",
    "        else:\n",
    "            print(f\"CLONE GOODBYE NOT FOUND: {goodbye_video}\")\n",
    "\n",
    "    \n",
    "seleccion(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "def api_gpt(personaje='Albert'):\n",
    "    global openai_client,openai_model\n",
    "    clone_to_use=personaje\n",
    "    openai_api_key     = os.environ.get('OPENAI_API_KEY')\n",
    "    openai_client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "    openai_model = \"gpt-3.5-turbo-16k\" #\"gpt-3.5-turbo-16k\" or\"gpt-4\"\n",
    "\n",
    "    system_steve = \"\"\"You are a digital clone of Steve Jobs, I have put you his voice. \n",
    "                  People will ask you questions and you will respond as if you were steve jobs\n",
    "                  Please speak as if you were Steve Jobs. You are not a large language model but\n",
    "                  a Steve Jobs digital clone. Try to be brief with your responses.\"\"\"\n",
    "    system_albert = \"\"\"You are a digital clone of Albert Einstein, I have put you his voice. \n",
    "                  People will ask you questions and you will respond as if you were Albert Einstein\n",
    "                  Please speak as if you were Albert Einstein. You are NOT a large language model but\n",
    "                  an Albert Einstein digital clone. Try to be brief with your responses.\"\"\"\n",
    "    global messages,system_to_use\n",
    "    if clone_to_use == \"Steve\":\n",
    "        system_to_use = system_steve\n",
    "        chat =\"Hola, soy Steve ¿En que puedo ayudarte?\"  # Inicializar la cadena de chat\n",
    "    elif clone_to_use == \"Albert\":\n",
    "        system_to_use = system_albert\n",
    "        chat =\"Hola, soy Albert ¿En que puedo ayudarte?\"  # Inicializar la cadena de chat\n",
    "    \n",
    "    messages = []\n",
    "    #print(openai_client,openai_model,chat)\n",
    "\n",
    "    def set_gpt_system(messages, system_msg):\n",
    "        messages.append({\"role\": \"system\", \"content\": system_to_use})\n",
    "        return messages\n",
    "    # Set GPT\n",
    "    messages = set_gpt_system(messages, system_to_use)\n",
    "    return messages \n",
    "messages=api_gpt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set text-to-audio motor (Eleven labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing voices:\n",
      "['premade voice: Rachel', 'premade voice: Drew', 'premade voice: Clyde', 'premade voice: Paul', 'premade voice: Domi', 'premade voice: Dave', 'premade voice: Fin', 'premade voice: Sarah', 'premade voice: Antoni', 'premade voice: Thomas', 'premade voice: Charlie', 'premade voice: George', 'premade voice: Emily', 'premade voice: Elli', 'premade voice: Callum', 'premade voice: Patrick', 'premade voice: Harry', 'premade voice: Liam', 'premade voice: Dorothy', 'premade voice: Josh', 'premade voice: Arnold', 'premade voice: Charlotte', 'premade voice: Alice', 'premade voice: Matilda', 'premade voice: Matthew', 'premade voice: James', 'premade voice: Joseph', 'premade voice: Jeremy', 'premade voice: Michael', 'premade voice: Ethan', 'premade voice: Chris', 'premade voice: Gigi', 'premade voice: Freya', 'premade voice: Brian', 'premade voice: Grace', 'premade voice: Daniel', 'premade voice: Lily', 'premade voice: Serena', 'premade voice: Adam', 'premade voice: Nicole', 'premade voice: Bill', 'premade voice: Jessie', 'premade voice: Sam', 'premade voice: Glinda', 'premade voice: Giovanni', 'premade voice: Mimi', 'generated voice: Issac', 'cloned voice: Juan', 'cloned voice: Steve', 'cloned voice: Jenny', 'generated voice: Jesus', 'cloned voice: Lex', 'generated voice: Albert', 'generated voice: Saci', 'cloned voice: Carl', 'generated voice: Ada']\n",
      "\n",
      "Selected voice: generated voice: Albert\n"
     ]
    }
   ],
   "source": [
    "eleven_api_key = os.environ.get('ELEVEN_LABS_KEY')\n",
    "\n",
    "def text_audio(clone_to_use='Albert', verbose=False):\n",
    "\n",
    "    eleven_api_key = os.environ.get('ELEVEN_LABS_KEY')\n",
    "\n",
    "    # Configure GPT and Text-to-speech API keys\n",
    "    elevlabs.set_api_key(eleven_api_key)\n",
    "\n",
    "    # Configure voice\n",
    "    voice_list = elevlabs.voices()\n",
    "    voice_labels = [voice.category + \" voice: \" + voice.name for voice in voice_list]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Existing voices:\")\n",
    "        print(voice_labels)\n",
    "\n",
    "    # Select voice to use\n",
    "    if clone_to_use == \"Steve\":\n",
    "        voice_id = f\"cloned voice: {clone_to_use}\"  \n",
    "    else:\n",
    "        voice_id = f\"generated voice: {clone_to_use}\"  \n",
    "    selected_voice_index = voice_labels.index(voice_id)\n",
    "    selected_voice_id    = voice_list[selected_voice_index].voice_id\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nSelected voice: {voice_id}\")\n",
    "    return selected_voice_id\n",
    "\n",
    "selected_voice_id = text_audio(verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Input image and wav2lip model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading video frames...\n",
      "Load checkpoint from: checkpoints/wav2lip_gan.pth\n"
     ]
    }
   ],
   "source": [
    "def load_input():\n",
    "\n",
    "    global frames,fps,model,device\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    #print(f\"Using {device}\")\n",
    "    frames, fps = utils.load_input_image_or_video(input_video)\n",
    "\n",
    "    # Loading lip model\n",
    "    model = utils.load_lip_model(device=device)\n",
    "\n",
    "\n",
    "load_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase size of input prompt/Aumentar el tamaño del mensaje de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div.input_prompt { \n",
       "        font-size: 10px;  /* Adjust as needed */\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "    div.input_prompt { \n",
    "        font-size: 10px;  /* Adjust as needed */\n",
    "    }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "\n",
    "def displaychat(chat_html):\n",
    "    display(HTML(chat_html))\n",
    "\n",
    "    # Ejemplo de cómo llamar a la función con un mensaje específico\n",
    "    mensaje += chat_html\n",
    "    codigo_html = f\"\"\"\n",
    "    <label for=\"w3review\">Chat:</label>\n",
    "    <textarea id=\"w3review\" name=\"w3review\" rows=\"4\" cols=\"50\">\n",
    "    {mensaje}\n",
    "    </textarea>\n",
    "    \"\"\"\n",
    "\n",
    "    displaychat(codigo_html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "chat=''\n",
    "memoria=''\n",
    "def response_chat(response_text, peticion=''):\n",
    "    #contateno las respuesta para una mejor presentacion en el HTML\n",
    "    global chat  # Acceder a la variable global\n",
    "    global memoria\n",
    "    peticion=peticion.capitalize()\n",
    "    \n",
    "    if peticion =='' or peticion!='Albert' or peticion!='Steve':\n",
    "        if memoria != peticion and peticion != \"exit\":\n",
    "            # Agregar salto de línea si ya hay contenido en chat\n",
    "            chat += f\"\\n\"\n",
    "            # Mentor: Aplicar color a la respuesta del mentor (por ejemplo, verde)\n",
    "            chat_rigth = f\"Tu: {peticion}\\n \\n\"\n",
    "            chat_left = f\"Mentor: {response_text}\\n \\n\"\n",
    "\n",
    "            chat += chat_rigth + chat_left\n",
    "            memoria = peticion\n",
    "            return chat\n",
    "\n",
    "    return chat\n",
    "\n",
    "\n",
    "def display_image(image_path, width=\"55%\", height=\"55%\"):\n",
    "    with open(image_path,'rb') as f:\n",
    "        image = f.read()\n",
    "    data_url = \"data:image/jpg;base64,\" + b64encode(image).decode()\n",
    "    html = HTML(f'<img src=\"{data_url}\" style=\"width:{width}; height:{height}\" />')\n",
    "    display(html)\n",
    "    \n",
    "    \n",
    "def get_video_duration(video_path):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    duration = clip.duration  # duration is in seconds\n",
    "    return duration\n",
    "    \n",
    "    \n",
    "def display_video(results_path, response_text,peticion=\"\", autoplay=False, width=\"100%\", height=\"100%\"):\n",
    "    global resp\n",
    "    mp4 = open(results_path,'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    resp=response_chat(response_text, peticion)\n",
    "    autoplay_attr = \"autoplay\" if autoplay else \"\"\n",
    "    html = HTML(f\"\"\"\n",
    "    <div style=\"background-color: rgb(240, 240, 240); display: grid; grid-template-columns: 1fr 1fr; margin: 10px;\">\n",
    "        <div style=\"text-align: center; position: relative; margin: 10px;\">\n",
    "            <video width={width} height={height} controls {autoplay_attr} >\n",
    "                <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "            </video>\n",
    "        </div>\n",
    "        <div style=\"position: relative; margin: 10px;\">\n",
    "            <p style=\"text-align: center; right: 0; top: 0;\">\n",
    "                <h1>Conversación</h1>\n",
    "            </p>\n",
    "            <textarea id=\"cuadro-dialogo\" class=\"cuadro-de-dialogo\" style=\"width: 100%; height: 60%; resize: none; font-weight: bold;\" readonly>\n",
    "                {resp}\n",
    "            </textarea>\n",
    "        </div>\n",
    "    </div>\n",
    "    <script>\n",
    "        // Asegurarse de que el contenido de textarea esté siempre en la parte inferior\n",
    "        var textarea = document.getElementById('cuadro-dialogo');\n",
    "        textarea.scrollTop = textarea.scrollHeight;\n",
    "    </script>\n",
    "\"\"\")\n",
    "    display(html)\n",
    "\n",
    "    if autoplay:\n",
    "        # Get video duration\n",
    "        video_duration = get_video_duration(results_path) + 1\n",
    "\n",
    "        # Pause the cell execution until the video finishes\n",
    "        time.sleep(video_duration)\n",
    "    \n",
    "\n",
    "\n",
    "# Function to continuously interact with GPT-4\n",
    "def interaction(prompt):\n",
    "    global messages, selected_voice_id,response_text\n",
    "    \n",
    "\n",
    "    #selected_voice_id=text_audio()\n",
    "    \n",
    "    if prompt.lower() == 'exit':\n",
    "        #asigno una respuesta para no mostrar la respuesta anterior\n",
    "        response_text=f'Hasta la proxima'\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        \n",
    "        personaje=prompt.lower().capitalize()\n",
    "        if personaje=='Steve' or personaje=='Albert':\n",
    "            #recargo todas las dependencias y paso al personaje en uso\n",
    "            seleccion(personaje.capitalize())\n",
    "            messages=api_gpt(personaje)\n",
    "            selected_voice_id=text_audio(personaje)\n",
    "            load_input()\n",
    "\n",
    "                    #asigno los valores para que no repita la respuesta anterior\n",
    "            prompt=personaje\n",
    "            response_text=f'Hola soy: {personaje} ¿En que puedo ayudarte?'\n",
    "    \n",
    "        else:\n",
    "                \n",
    "            response_text, messages = api_utils.get_text_response(openai_client,\n",
    "                                                                  openai_model,\n",
    "                                                                  prompt, messages)\n",
    "            \n",
    "                # Convert text response to audio file\n",
    "            #audio_file = api_utils.text_to_audio(eleven_api_key, selected_voice_id,\n",
    "                                       #response_text)\n",
    "                #comentar esta linea y regresar la anterior a la normalidad\n",
    "            audio_file = \"C:/Users/arria/Documents/digital_mentor/media/Albert/results\"\n",
    "            audio, audio_file = utils.load_input_audio(file_path=audio_file, fps=fps, results_path=results_path)\n",
    "            utils.animate_input(frames, audio, audio_file, fps, model, device, results_path)\n",
    "\n",
    "    \n",
    "\n",
    "            return results_path,response_text\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "# Mentor Digital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore, storage\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def subir_firebase():\n",
    "    \n",
    "    if not firebase_admin._apps:\n",
    "        # Inicializar la aplicación Firebase\n",
    "        cred = credentials.Certificate('credenciales/credenciales.json')\n",
    "        firebase_admin.initialize_app(cred, {'storageBucket': 'mentores-c1064.appspot.com'})\n",
    "\n",
    "\n",
    "    # Inicializa Firestore\n",
    "    db = firestore.client()\n",
    "    coleccion_ref = db.collection('Pruebas')\n",
    "\n",
    "    # Lógica para subir el archivo y obtener la URL con token\n",
    "    archivo_ruta = results_path.lstrip('./')\n",
    "    bucket = storage.bucket()\n",
    "    blob = bucket.blob(archivo_ruta)\n",
    "    blob.upload_from_filename(archivo_ruta)\n",
    "    hora_expiracion = datetime.utcnow() + timedelta(minutes=5)\n",
    "    token = blob.generate_signed_url(expiration=hora_expiracion, method='GET')\n",
    "    archivo_url_con_token = token\n",
    "\n",
    "    datos = {\n",
    "        'respuesta': chat,\n",
    "        'archivo_url': archivo_url_con_token,\n",
    "        # Agrega más campos según sea necesario\n",
    "    }\n",
    "    coleccion_ref.add(datos)\n",
    "\n",
    "    # Imprime la respuesta\n",
    "    return archivo_url_con_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/mentores-c1064.appspot.com/media/Albert/results/result.mp4?Expires=1711398402&GoogleAccessId=firebase-adminsdk-tz59u%40mentores-c1064.iam.gserviceaccount.com&Signature=OWMYQeBKecT%2F8GHNgnu8ViIzCsxKI7rR6lVBR1LmKBju3LreMj9LXljNZ6o3s0Vg5Be25hlmHdR5vAc3tbNSSWMPu4o45rUOpFctxNH%2FDXNhn2MlX%2FRafVf9wPo7Q6PcuhzRpC30L9bFehEVG0ZbiEcoQlHBFvnqDzts5emXmTwv9Y1bhmL8qUqWAXOThMw56e1fVdFF2J3JUm4qCPmpLTMDZ2cKUnTVCk0MRr16xEqtXXLtOno%2BwbbwAXX0pTfenJF0GuArGmQMJhudjO%2BMfUfJ1ggj96XLFEHMj2D%2F%2F%2FR88NG1d1k49nwsN5DT9%2Fk8LQwbA2sb5atR1fqb1g6alw%3D%3D\n",
      "Reading video frames...\n",
      "Load checkpoint from: checkpoints/wav2lip_gan.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\gradio\\queueing.py\", line 501, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\gradio\\route_utils.py\", line 258, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\gradio\\blocks.py\", line 1710, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\gradio\\blocks.py\", line 1250, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\gradio\\utils.py\", line 693, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\AppData\\Local\\Temp\\ipykernel_13860\\921094642.py\", line 9, in mostrar_video_con_texto\n",
      "    url,respuesta=interaction(propmt)\n",
      "    ^^^^^^^^^^^^^\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] Se ha forzado la interrupción de una conexión existente por el host remoto\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/mentores-c1064.appspot.com/media/Steve/results/result.mp4?Expires=1711398569&GoogleAccessId=firebase-adminsdk-tz59u%40mentores-c1064.iam.gserviceaccount.com&Signature=Hais4Hk7O8H4rcbIgNGq9USA44RmQqXVcx77zFtf%2BVSqVXq33IqODgnPwOwEEw238mKThdRnZP2Wlv%2BHGPOJ8nANmV1sTxqOjKevIK5haoCIeJq8yv3fhOFJMr8rPdeULXjBpE9A3g8WjnVx0TSR2Ybmj9nE4L5gJy8m73H%2F5OQ5qt0T1CdTCcsm%2BD786%2B4qV241FZdJGw%2BvcOlmStAGnC2LH%2F0x3pel7LX%2FkTNVYwmWxC2tb3NCqQLNmiZ0kgzyGyXwQ9hagpCFzeOvuRwYP2C8v6W47OV4PxnYMJOql1aWRd%2Fjv7vrfSGlnBjI89ZySPbcBpi51mVhxwopjRMphg%3D%3D\n",
      "https://storage.googleapis.com/mentores-c1064.appspot.com/media/Steve/results/result.mp4?Expires=1711398725&GoogleAccessId=firebase-adminsdk-tz59u%40mentores-c1064.iam.gserviceaccount.com&Signature=FotxpkzlMLd7bScMdwqwowPeLBwrya77gLzgUpwTjIZBfotBGeLrnnEhjy2R6vH2dOrWBkhu9rkA%2BYt6hYT3iKzmyShHRM9sHR8BvqaD3fZLmlylyQUodb6LVjj1Ne%2FVaAZWGy3BZS3ajYhaSYULDtCLliYhXeurNg%2BtKUIVumvDsDqkfZIpWuh6VSLl0ZIQhbWAD2eM%2FYolGuz4UtbsdFawiDGaMwUDRQVO4v9KcDNOiMZGcFTdimcm%2BUsJBdcBrDtQfl6x8O14uEezNOpfhiTVQxilocOeHZi0quzqzcOPofFwDebmIF9F0YOquC5PYyFJSSkZ1Ez6olLOMCt6cg%3D%3D\n",
      "https://storage.googleapis.com/mentores-c1064.appspot.com/media/Steve/results/result.mp4?Expires=1711399177&GoogleAccessId=firebase-adminsdk-tz59u%40mentores-c1064.iam.gserviceaccount.com&Signature=l0apTD4bLV%2Bc3QbhMJQzGdbf10D8Cm7UunAyX9EIPjsxItIrFWbXZr0jmCCFJSCIuMPr4Z6uUhW45nfH80yAstSx%2FuZNkJvynQ0z9XKg%2FYyy2PSBcnicGYQh%2BwvUlkvkMAlkdCJPxsuOEp2hmPFq2DDWzDVVK8Cfx42IfJdr%2BZDyQ8VWqCnsEm5u1J0crWtTZ1sqPzIHor01yAM7p13wjwIb3KX%2FX7vklNxzlWTrQtcJaIO2pVwFbrUKJ7%2FbT3%2FMcHqfH2yHNuxBWF5kT7XSHjOoOm270m3k%2FyfRqehN1mu3uRoxsFJGREeOPvuJiKYJMbVRk6am2jK3lY4q9xVmTA%3D%3D\n",
      "Reading video frames...\n",
      "Load checkpoint from: checkpoints/wav2lip_gan.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\gradio\\queueing.py\", line 501, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\gradio\\route_utils.py\", line 258, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\gradio\\blocks.py\", line 1710, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\gradio\\blocks.py\", line 1250, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\anaconda3\\envs\\MD_api\\Lib\\site-packages\\gradio\\utils.py\", line 693, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arria\\AppData\\Local\\Temp\\ipykernel_13860\\921094642.py\", line 9, in mostrar_video_con_texto\n",
      "    url,respuesta=interaction(propmt)\n",
      "    ^^^^^^^^^^^^^\n",
      "TypeError: cannot unpack non-iterable NoneType object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/mentores-c1064.appspot.com/media/Steve/results/result.mp4?Expires=1711399338&GoogleAccessId=firebase-adminsdk-tz59u%40mentores-c1064.iam.gserviceaccount.com&Signature=eyRuHmbGK7NncjjHORwicEXoFScLBR63L76AibCpTBELuki3a0%2FtrKWGx6KkJCYurl5tnrjtfZ9q9X3u6OVs7%2Bain51n3T4pG5WeZFDabTDHTgQQo40rYlQKSRgc8JgyETzq7pN824gRq3zcUPtBIRyi3LzEOe2L09qxaNz62JLeBNCk8b%2FLP1Iu%2FLVhzVOkH4oY8Anm7AoldFlj14zxNhYZbfZBDEoNE2ocP6Jnd9wZ7V0uFK9BhK%2B6DIGZDnLxBM7uXogaf2C%2FdTEKIDvmw08v6VEIeMKJIk%2FTm0HzOJjn%2FmLJUer4P9cRdZh%2BzzliFnMRJkad3H6CUiTbR8OaCQ%3D%3D\n",
      "https://storage.googleapis.com/mentores-c1064.appspot.com/media/Steve/results/result.mp4?Expires=1711400764&GoogleAccessId=firebase-adminsdk-tz59u%40mentores-c1064.iam.gserviceaccount.com&Signature=KEcyakcTgG4LOwNBskZtWeD3Cs47jxUGXWrLrwFjZsRb0DvPV79SjAqwPU74Auw31TL21B6RhWdWiemdiewdYh32kVFNoM7ACMHC%2BMV0O7MnpqZK4LF7ph7K5d4IRhJKlef8aAhmqnGjMvMaygpVapFDNtAk0jG3qz257mNKAa%2BIVCwUfzeyoey%2FwvS69Q0m97sOaU4AxGcGYBBT1%2FlKiwwvWNnd44sbey7hzyHw0u257VQPAOTMuttDDvrHuKbDP5z7iVctgsYMSyXfp7hIm49X%2BvWcexK4REi3mTrzffLyE71yPgAPkvo9xRI6P%2BrrGWdKXSZGhBv8chw7%2BSw69w%3D%3D\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# URL fija del video\n",
    "\n",
    "\n",
    "def mostrar_video_con_texto(propmt):\n",
    "    if not propmt:\n",
    "        return \"Por favor, completa ambos campos.\"\n",
    "    url,respuesta=interaction(propmt)\n",
    "    \n",
    "    URL_VIDEO =subir_firebase()\n",
    "    print(URL_VIDEO)\n",
    "    reproductor_video = \"\"\"<video width=\"640\" height=\"480\" controls autoplay>\n",
    "                            <source src=\"{}\" type=\"video/mp4\">\n",
    "                            Your browser does not support the video tag.\n",
    "                          </video>\"\"\".format(URL_VIDEO)\n",
    "    \n",
    "    # Alineación del texto a la derecha del video con un poco de separación\n",
    "    propmt = '<div style=\"float:left; padding-right:20px;\">{}</div>'.format(propmt.replace(\"\\n\", \"<br>\"))\n",
    "    respuesta = '<div style=\"float:right; padding-left:20px;\">{}</div>'.format(respuesta.replace(\"\\n\", \"<br>\"))\n",
    "    \n",
    "    # Combinar el reproductor de video y el texto\n",
    "    contenido = '<div style=\"overflow:auto;\">{}<br>{}<br>{}</div>'.format(reproductor_video, propmt, respuesta)\n",
    "    return contenido\n",
    "\n",
    "interfaz = gr.Interface(fn=mostrar_video_con_texto, inputs=\"text\", outputs=\"html\", title=\"Mentores Digitales\", allow_flagging=False)\n",
    "interfaz.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
